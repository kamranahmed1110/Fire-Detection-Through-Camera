{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39b5a6d-ce4d-40c5-911f-a6342a6014f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from yolo_predictions import YOLO_pred\n",
    "\n",
    "#yolo = YOLO_pred('./Model/weights/best.onnx','data.yaml')\n",
    "\n",
    "#img = cv2.imread('./firee.jpg')\n",
    "#cv2.imshow('img',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "#img_pred = yolo.predictions(img)\n",
    "\n",
    "#cv2.imshow('prediction image', img_pred)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993d5457-b641-4a26-9868-c58cb8362a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO_pred('./Model/weights/best.onnx','data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132d2f4f-9707-4b1c-af6d-5d3b66b50a99",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./ffff.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./ffff.jpg')\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a81def-4f2f-4087-867b-8c1f2cab944a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_pred \u001b[38;5;241m=\u001b[39m \u001b[43myolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\FYProject\\predictions\\yolo_predictions.py:75\u001b[0m, in \u001b[0;36mYOLO_pred.predictions\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     72\u001b[0m boxes_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(boxes)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     73\u001b[0m confidences_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(confidences)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 75\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNMSBoxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidences_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.45\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m index:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# extract bounding boxes\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     x, y, w, h \u001b[38;5;241m=\u001b[39m boxes_np[ind]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "img_pred = yolo.predictions(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07a187b-d577-427e-a2af-e46df306bbef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction image\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mimg_pred\u001b[49m)\n\u001b[0;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_pred' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow('prediction image', img_pred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432a5666-f5c0-4680-8a43-2ee483769b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred():\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # load YAML \n",
    "        with open('data.yaml', mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "          \n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "    \n",
    "        # load yolo model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX('./Model/weights/best.onnx')\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):   \n",
    "        # get yolo prediction from the frame\n",
    "        # step 1: convert frame into square img (array)\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame \n",
    "\n",
    "        # step 2: get prediction from square array\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # detection or prediction from yolo \n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # width and height of the frame(input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # maximum probability of the object \n",
    "                class_id = row[5:].argmax()  # get the index position at which max probability occur\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # construct bounding box from four values\n",
    "                    # left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "            \n",
    "                    box = np.array([left, top, width, height])\n",
    "            \n",
    "                    # append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)  # Convert to numpy array\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        index = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.tolist(), 0.25, 0.45).flatten()\n",
    "\n",
    "        # Draw bounding boxes and labels on the frame\n",
    "        for ind in index:\n",
    "            # extract bounding boxes\n",
    "            x, y, w, h = boxes_np[ind]\n",
    "            bb_conf = int(confidences_np[ind] * 100)\n",
    "            classes_id = classes[ind]\n",
    "            class_name = self.labels[classes_id]\n",
    "            colors = self.generate_colors(classes_id)\n",
    "\n",
    "            text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2) \n",
    "            cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "            cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f91be9-7185-4608-8c6b-48c204d4ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        for i in range(len(nms_result)):\n",
    "            ind = nms_result[i][0]\n",
    "\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            x, y, w, h = boxes_np[ind]\n",
    "            bb_conf = int(confidences_np[ind] * 100)\n",
    "            classes_id = classes[ind]\n",
    "            class_name = self.labels[classes_id]\n",
    "            colors = self.generate_colors(classes_id)\n",
    "\n",
    "            text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2)\n",
    "            cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "            cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Open camera\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default camera, change it if you have multiple cameras\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform predictions on the frame\n",
    "        frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "        # Display the frame with predictions\n",
    "        cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "        \n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e8a3f0d-4382-475c-9474-7a0b6c20d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real time code\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        if len(nms_result) > 0:\n",
    "            index = nms_result.flatten()\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            for ind in index:\n",
    "                # Extract bounding boxes\n",
    "                x, y, w, h = boxes_np[ind]\n",
    "                bb_conf = int(confidences_np[ind] * 100)\n",
    "                classes_id = classes[ind]\n",
    "                class_name = self.labels[classes_id]\n",
    "                colors = self.generate_colors(classes_id)\n",
    "\n",
    "                text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2)\n",
    "                cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "                cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Open camera\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default camera, change it if you have multiple cameras\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform predictions on the frame\n",
    "        frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "        # Display the frame with predictions\n",
    "        cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "        \n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce87d5bf-f620-451c-9436-a18cce9ffa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video code\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        if len(nms_result) > 0:\n",
    "            index = nms_result.flatten()\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            for ind in index:\n",
    "                # Extract bounding boxes\n",
    "                x, y, w, h = boxes_np[ind]\n",
    "                bb_conf = int(confidences_np[ind] * 100)\n",
    "                classes_id = classes[ind]\n",
    "                class_name = self.labels[classes_id]\n",
    "                colors = self.generate_colors(classes_id)\n",
    "\n",
    "                text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2)\n",
    "                cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "                cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Path to the input video file\n",
    "    video_file = 'fire.mp4'\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform predictions on the frame\n",
    "        frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "        # Display the frame with predictions\n",
    "        cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "        \n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb7b9c2-e02f-4dff-8810-9166598d6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        if len(nms_result) > 0:\n",
    "            index = nms_result.flatten()\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            for ind in index:\n",
    "                # Extract bounding boxes\n",
    "                x, y, w, h = boxes_np[ind]\n",
    "                bb_conf = int(confidences_np[ind] * 100)\n",
    "                classes_id = classes[ind]\n",
    "                class_name = self.labels[classes_id]\n",
    "                colors = self.generate_colors(classes_id)\n",
    "\n",
    "                text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2)\n",
    "                cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "                cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Path to the input video file\n",
    "    video_file = 'fire.mp4'\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform predictions on the frame\n",
    "        frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "        # Display the frame with predictions\n",
    "        cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "        \n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e37874b2-d85b-44a2-8e57-40d373f7e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        if len(nms_result) > 0:\n",
    "            index = nms_result.flatten()\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            for ind in index:\n",
    "                # Extract bounding boxes\n",
    "                x, y, w, h = boxes_np[ind]\n",
    "                bb_conf = int(confidences_np[ind] * 100)\n",
    "                classes_id = classes[ind]\n",
    "                class_name = self.labels[classes_id]\n",
    "                colors = self.generate_colors(classes_id)\n",
    "\n",
    "                text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2)\n",
    "                cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "                cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Path to the input video file\n",
    "    video_file = 'short.mp4'\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform predictions on the frame\n",
    "        frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "        # Display the frame with predictions\n",
    "        cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "        \n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93443510-8eff-4e83-9508-b36852823024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting imageL\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        if len(nms_result) > 0:\n",
    "            index = nms_result.flatten()\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            for ind in index:\n",
    "                # Extract bounding boxes\n",
    "                x, y, w, h = boxes_np[ind]\n",
    "                bb_conf = int(confidences_np[ind] * 100)\n",
    "                classes_id = classes[ind]\n",
    "                class_name = self.labels[classes_id]\n",
    "                colors = self.generate_colors(classes_id)\n",
    "\n",
    "                text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), colors, 2)\n",
    "                cv2.rectangle(frame, (x, y-30), (x+w, y), colors, -1)\n",
    "                cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Path to the input image file\n",
    "    image_file = 'design.jpg'\n",
    "\n",
    "    # Read the input image\n",
    "    frame = cv2.imread(image_file)\n",
    "\n",
    "    # Perform predictions on the image\n",
    "    frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "    # Display the image with predictions\n",
    "    cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "709cdc43-4cd6-4efe-b288-04a6277939d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for detecting image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "class YOLO_pred:\n",
    "    def __init__(self, onnx_model, data_yaml):\n",
    "        # Load YAML\n",
    "        with open(data_yaml, mode='r') as f:\n",
    "            data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "    def predictions(self, frame):\n",
    "        # Resize the frame to a reasonable size to ensure faster processing\n",
    "        frame_resized = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        # Get YOLO prediction from the frame\n",
    "        row, col, d = frame_resized.shape\n",
    "        max_rc = max(row, col)\n",
    "        input_image = np.zeros((max_rc, max_rc, 3), dtype=np.uint8)\n",
    "        input_image[0:row, 0:col] = frame_resized\n",
    "\n",
    "        # Resize the image to fit YOLO input size\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WH_YOLO, INPUT_WH_YOLO), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward()  # Detection or prediction from YOLO\n",
    "\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        # Width and height of the frame (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w / INPUT_WH_YOLO\n",
    "        y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4]  # Confidence of detecting an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max()  # Maximum probability of the object\n",
    "                class_id = row[5:].argmax()  # Get the index position at which max probability occurs\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # Construct bounding box from four values: left top width height\n",
    "                    left = int((cx - 0.5*w) * x_factor)\n",
    "                    top = int((cy - 0.5*h) * y_factor)\n",
    "                    width = int(w * x_factor)\n",
    "                    height = int(h * y_factor)\n",
    "\n",
    "                    box = np.array([left, top, width, height])\n",
    "\n",
    "                    # Append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # Clean the data\n",
    "        boxes_np = np.array(boxes)\n",
    "        confidences_np = np.array(confidences)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        nms_result = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.flatten().tolist(), 0.25, 0.45)\n",
    "        if len(nms_result) > 0:\n",
    "            index = nms_result.flatten()\n",
    "            # Draw bounding boxes and labels on the frame\n",
    "            for ind in index:\n",
    "                # Extract bounding boxes\n",
    "                x, y, w, h = boxes_np[ind]\n",
    "                bb_conf = int(confidences_np[ind] * 100)\n",
    "                classes_id = classes[ind]\n",
    "                class_name = self.labels[classes_id]\n",
    "                colors = self.generate_colors(classes_id)\n",
    "\n",
    "                text = f'{class_name}:{bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(frame_resized, (x, y), (x+w, y+h), colors, 2)\n",
    "                cv2.rectangle(frame_resized, (x, y-30), (x+w, y), colors, -1)\n",
    "                cv2.putText(frame_resized, text, (x, y-10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "                        \n",
    "        return frame_resized\n",
    "\n",
    "    def generate_colors(self, ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100, 255, size=(self.nc, 3)).tolist()\n",
    "        return tuple(colors[ID])\n",
    "\n",
    "def main():\n",
    "    # Paths to the ONNX model and data YAML\n",
    "    onnx_model = './Model/weights/best.onnx'\n",
    "    data_yaml = 'data.yaml'\n",
    "\n",
    "    yolo_detector = YOLO_pred(onnx_model, data_yaml)\n",
    "\n",
    "    # Path to the input image file\n",
    "    image_file = 'firee.jpg'\n",
    "\n",
    "    # Read the input image\n",
    "    frame = cv2.imread(image_file)\n",
    "\n",
    "    # Perform predictions on the image\n",
    "    frame_with_predictions = yolo_detector.predictions(frame)\n",
    "\n",
    "    # Display the image with predictions\n",
    "    cv2.imshow('YOLO Fire Detection', frame_with_predictions)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0748e-f52f-452b-b458-09d1a650b32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
